{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##\n",
      "## Variables:\n",
      "##\n",
      "## search_url contains the initial search string. In this case we\n",
      "## are searching for all of the guides published by the BU Libraries\n",
      "## on the Libraries' web site:  * inurl:www.bu.edu/library/guide/\n",
      "search_url = 'http://www.bu.edu/phpbin/search/?t=default&dir=1&maps=1&q=*+inurl%3Awww.bu.edu%2Flibrary%2Fguide%2F'\n",
      "##\n",
      "## results_url contains the results of the initial search. To this string\n",
      "## we will append the total number of results parsed from the initial\n",
      "## results page.\n",
      "results_url = 'http://www.bu.edu/phpbin/search/index.php?q=*+inurl:www.bu.edu/library/guide/&start=0&col=default_collection&site=&t=default&sort=&dir=1&maps=1&num='\n",
      "##\n",
      "## Test will print the values if true\n",
      "test = False\n",
      "\n",
      "## Import the required libraries\n",
      "import os\n",
      "import urllib2\n",
      "from pymarc import Field, Record\n",
      "from BeautifulSoup import BeautifulSoup\n",
      "import cgi\n",
      "import tarfile\n",
      "# setup a variable for excaping HTML chars\n",
      "html_escape_table = {\n",
      "                     \"&\": \"&amp;\",\n",
      "                     '\"': \"&quot;\",\n",
      "                     \"'\": \"&apos;\",\n",
      "                     \">\": \"&gt;\",\n",
      "                     \"<\": \"&lt;\",\n",
      "                     }\n",
      "## define a function that will escape strings of text for use in xml\n",
      "def html_escape(text):\n",
      "    \"\"\"Produce entities within text.\"\"\"\n",
      "    return \"\".join(html_escape_table.get(c,c) for c in text) \n",
      "\n",
      "if not test:\n",
      "    ## open the xml file and write the header\n",
      "    f = open('guides.xml', 'wb')\n",
      "    f.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
      "    f.write('<OAI-PMH xmlns=\"http://www.openarchives.org/OAI/2.0/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd\">\\n')\n",
      "    f.write('<responseDate>2014-07-09T21:02:57Z</responseDate>\\n')\n",
      "    f.write('    <request verb=\"ListRecords\" metadataPrefix=\"oai_dc\" >http://www.bu.edu/library/guides</request>\\n')\n",
      "    f.write('<ListRecords>\\n')\n",
      "\n",
      "\n",
      "\n",
      "## read the results list to get the number of results\n",
      "page = urllib2.urlopen(search_url)\n",
      "rpage = page.read()\n",
      "soup =  BeautifulSoup(rpage)\n",
      "num_hits = soup.fetch('span', {'class' : 'hits'})\n",
      "num_hits = num_hits[0].text\n",
      "num_hits = int(num_hits[num_hits.rfind('y')+1:])\n",
      "print num_hits\n",
      "## Get the full list of guides\n",
      "results_url += str(num_hits)\n",
      "page = urllib2.urlopen(results_url)\n",
      "rpage = page.read()\n",
      "soup =  BeautifulSoup(rpage)\n",
      "## grab all of the 'a' tags\n",
      "a_list = soup.fetch('a')\n",
      "##a_list = soup.find_all('a')\n",
      "#a_list = soup(\"a\")\n",
      "href_dict = {}\n",
      "href_list = []\n",
      "for a in a_list:\n",
      "    if a['href'][:4] == 'http':\n",
      "        href_dict[a['href']] = 'url'\n",
      "href_list = list(href_dict.keys())\n",
      "\n",
      "##\n",
      "counter = 1\n",
      "for href in href_list:\n",
      "    page = urllib2.urlopen(href)\n",
      "    rpage = page.read()\n",
      "    info = page.info()\n",
      "    date = info['date']\n",
      "    date = date[5:-12]\n",
      "    soup =  BeautifulSoup(rpage)\n",
      "    ## get the title\n",
      "    title = soup.title.contents[0]\n",
      "    title = title[:-41]\n",
      "\n",
      "    ## author\n",
      "    author = ''\n",
      "    authors = soup.findAll('div', {'class' : 'widget bu-library-profiles-widget guide_authors'})\n",
      "    if len(authors) > 0 :\n",
      "        authors = authors[0]\n",
      "        authors_list = authors.fetch('h3')\n",
      "        for a in authors_list:\n",
      "            if len(author) > 0:\n",
      "                author += '; '\n",
      "        author += a.a.contents[0]\n",
      "    ## subjects\n",
      "    subs = ''\n",
      "    subjects = soup.findAll('div', {'class' : 'widget bu-library-subjects-widget'})\n",
      "    if len(subjects) > 0:\n",
      "        subs_ul = subjects[0].ul\n",
      "        subs_ul.findAll('li')\n",
      "        for li in subs_ul.findAll('li'):\n",
      "            if len(subs) > 0:\n",
      "                subs += ';  '\n",
      "            subs += li.a.contents[0]\n",
      "    url = href\n",
      "    metaList = soup.fetch('meta')\n",
      "    meta_desc = ''\n",
      "    meta_keywords = ''\n",
      "    meta_rights = ''\n",
      "    for l in metaList:\n",
      "        meta = l.attrs\n",
      "        if len(meta) == 2:\n",
      "            #print meta\n",
      "            if meta[0][1] == 'description':\n",
      "                meta_desc = meta[1][1]\n",
      "               # print 'meta_desc: ' , meta_desc\n",
      "            if meta[0][1] == 'keywords':\n",
      "                meta_keywords = meta[1][1]\n",
      "               # print 'meta_key:  ', meta_keywords  \n",
      "            if meta[0][1] == 'Copyright':\n",
      "                meta_rights = meta[1][1]\n",
      "                #print 'meta_rights:  ', meta_rights\n",
      "\n",
      "    if not test:\n",
      "        f.write('<record>\\n')\n",
      "        f.write('<header>\\n')\n",
      "        f.write('<identifier>\\n')\n",
      "        #id = d.entries[i].id\n",
      "        id = 'libguide:' + str(counter)\n",
      "        f.write(html_escape(id))\n",
      "        f.write('</identifier>\\n')\n",
      "        f.write('<datestamp>2009-09-19T06:00:13Z</datestamp>\\n')\n",
      "        f.write('</header>\\n')\n",
      "        f.write('<metadata>\\n')\n",
      "        f.write('<oai_dc:dc xmlns:oai_dc=\"http://www.openarchives.org/OAI/2.0/oai_dc/\" xmlns:doc=\"http://www.lyncode.com/xoai\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xsi:schemaLocation=\"http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd\">\\n')\n",
      "        f.write('<dc:title>')\n",
      "        f.write(html_escape(title.encode('utf-8')))\n",
      "        f.write('</dc:title>\\n')\n",
      "        f.write('<dc:type>')\n",
      "        f.write('guide')\n",
      "        f.write('</dc:type>\\n')\n",
      "        if len(author) > 0:\n",
      "            f.write('<dc:creator>')\n",
      "            f.write(html_escape(author.encode('utf-8')))\n",
      "            f.write('</dc:creator>\\n')  \n",
      "        if len(subs) > 0:\n",
      "            f.write('<dc:subject>')\n",
      "            f.write(html_escape(subs.encode('utf-8')))\n",
      "            f.write('</dc:subject>\\n')\n",
      "        f.write('<dc:identifier>')\n",
      "        f.write(url)\n",
      "        f.write('</dc:identifier>\\n') \n",
      "        f.write('<dc:date>')\n",
      "        f.write(date)\n",
      "        f.write('</dc:date>') \n",
      "        f.write('<dc:subject>')\n",
      "        f.write('research guide')\n",
      "        f.write('</dc:subject>\\n')\n",
      "        if len(meta_desc) > 0:\n",
      "            f.write('<dc:description>')\n",
      "            f.write(html_escape(meta_desc.encode('utf-8')))\n",
      "            f.write('</dc:description>\\n') \n",
      "        if len(meta_keywords) > 0:\n",
      "            f.write('<dc:subject>')\n",
      "            f.write(html_escape(meta_keywords.encode('utf-8')))\n",
      "            f.write('</dc:subject>\\n') \n",
      "        f.write('</oai_dc:dc>\\n</metadata>\\n</record>\\n')\n",
      "        counter += 1\n",
      "    if test:\n",
      "        # lets see what we have\n",
      "        print 'record: ', str(counter)\n",
      "        print 'title: ', title\n",
      "        print 'author: ', author\n",
      "        print 'subject: ', subs\n",
      "        print 'summary: '\n",
      "        print 'keywords:'\n",
      "        print 'description: '\n",
      "        print 'link: ', url\n",
      "        print 'rights: ', meta_rights\n",
      "        print 'date: ', date\n",
      "        print ' '\n",
      "        counter += 1\n",
      "if not test:\n",
      "    f.write('</ListRecords>\\n')\n",
      "    f.write('</OAI-PMH>\\n')\n",
      "    f.close()\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "795\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}